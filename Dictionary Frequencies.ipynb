{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem.cistem import Cistem\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import os\n",
    "from pandas import read_csv\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dict_zurich\n",
    "from dict_zurich import emotional_dictionary, positive_data_list_stemmed, negative_data_list_stemmed,positive_data_list_cleaned\n",
    "from dict_zurich import negative_data_list_cleaned\n",
    "from dict_zurich import dict_neg_words, dict_pos_words, dict_neg_words_stemmed, dict_pos_words_stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dictionary Frequencies\n",
    "\n",
    "The following piece of research did not make it to the official publication. However, it was still interesting to see what kind of emotionally charged vocabulary sources use depending on their political affiliation. At the bottom of this notebook, you can find the frequency dictionary insights that we got after cleaning the output and making some sense of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_pos_neg_values_stemmed = negative_data_list_stemmed + positive_data_list_stemmed + emotional_dictionary[1] + dict_neg_words_stemmed + dict_pos_words_stemmed\n",
    "list_of_pos_neg_values_unstemmed = negative_data_list_cleaned + positive_data_list_cleaned + emotional_dictionary[0] + dict_pos_words + dict_neg_words\n",
    "list_of_empty_values = [0]*len(list_of_pos_neg_values_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_of_freq(direct):\n",
    "    \n",
    "    \"\"\"this function returns a frequency dictionary for\n",
    "    a corpus located in the passed directory; it also \n",
    "    solves the problem with stemmed and unstemmed words, \n",
    "    removing some coincidental matches\"\"\"\n",
    "    \n",
    "    dictionary_of_freq_stemmed = {}\n",
    "    dictionary_of_keywords = dict(zip(list_of_pos_neg_values_stemmed,list_of_empty_values))\n",
    "    dictionary_of_stem_to_unstem = {}\n",
    "    \n",
    "    for file in os.listdir(direct):\n",
    "        if file.endswith(\".txt\"):\n",
    "            text = open(direct + file, encoding=\"utf8\")\n",
    "            tokenizer = RegexpTokenizer(r'\\w+')\n",
    "            stemmer = Cistem()\n",
    "            text = [tokenizer.tokenize(word) for word in text]\n",
    "            text = list(filter(None, text))\n",
    "            text = list(itertools.chain.from_iterable(text))\n",
    "            unstemmed_text = text\n",
    "            text = [stemmer.stem(word) for word in text]\n",
    "            for i, stemmed_word in enumerate(text): \n",
    "                if stemmed_word in dictionary_of_keywords:\n",
    "                    unstemmed_word = unstemmed_text[i]\n",
    "                    if stemmed_word in dictionary_of_freq_stemmed:\n",
    "                        dictionary_of_freq_stemmed[stemmed_word] += 1\n",
    "                        if unstemmed_word in dictionary_of_stem_to_unstem[stemmed_word]:\n",
    "                            pass\n",
    "                        else:\n",
    "                            dictionary_of_stem_to_unstem[stemmed_word].append(unstemmed_word)\n",
    "                    else:\n",
    "                        dictionary_of_freq_stemmed[stemmed_word] = 1\n",
    "                        dictionary_of_stem_to_unstem[stemmed_word] = [unstemmed_word]\n",
    "\n",
    "\n",
    "    final_dictionary_of_freq = {key:[val, dictionary_of_stem_to_unstem[key]] for key, val in dictionary_of_freq_stemmed.items()}\n",
    "    freq = [small_list[0] for small_list in list(final_dictionary_of_freq.values())]\n",
    "    word = [small_list[1] for small_list in list(final_dictionary_of_freq.values())]\n",
    "    dict_merged = {k: v for k, v in zip(freq, word)}\n",
    "    dict_merged = {key:val for key,val in sorted(dict_merged.items(), key=lambda item: item[0], reverse = True)}\n",
    "\n",
    "    return dict_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stern_freq_dic = dict_of_freq('./texts/stern/')\n",
    "taz_freq_dic = dict_of_freq('./texts/')\n",
    "dk_freq_dic = dict_of_freq('./texts/deutschland kurier/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "taz = pd.DataFrame.from_dict(taz_freq_dic,orient='index').transpose()\n",
    "taz.to_excel('taz_dict_freq.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Below are some insights into the frequencies in our corpora\n",
    "\n",
    "Taz | Deutschland Kurier | Stern\n",
    "---|---|---\n",
    "Hilfe (145) | illegal (98) | retten (89)\n",
    "Anzeige (83) | Abschiebung (91) | arm (62)\n",
    "Haus (74) | fordern (76)| Kampf (55)\n",
    "Abschiebung (73) | links (72) | Recht (53)\n",
    "Problem (71) | Gesetz (66) | Gesetz (50)\n",
    "Gesetz (70) | Bürger (63) | Kritik (40)\n",
    "Schutz (59)| Recht (60) | Lösung (33)\n",
    "Recht (58)| Straftat (51) | Tod (32)\n",
    "Gefahr (54)| erhalten (47) | Solidarität (24)\n",
    "offen (52)| Gewalt (40) | Hilfe (23)\n",
    "\n",
    "The following is just some speculations, and yet, they are quite curious. \n",
    "\n",
    "#### Taz\n",
    "For the liberal source, Taz, we see that the discourse about refugees revolves around *help* (Hilfe) and *complaints* (Anzeige). Housing is a big topic as well as refugees' *rights* and *legislation* regarding their presence in their country. Overall, the liberal source seems to be more compassionate to refugees and defend their rights; \n",
    "\n",
    "#### Deutschland Kurier\n",
    "The conservative source, Deutschland Kurier, is pretty straightforward about the association between refugees and illegal activities. Abschiebung (sending them home) comes close second. There are many mentions of crime and violence as well as appeals to law and human rights. \n",
    "\n",
    "#### Stern\n",
    "The socia-democratic Stern shows compassion to refugees (arm - poor) and discusses their rescue a lot (retten). The vocabulary is also decidedly more negative than that of the other sources. It contains words such as war (Kampf) and death (Tod).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
